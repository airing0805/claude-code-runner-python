# 任务调度 - 存储层设计

> 本文档定义任务调度系统的存储层设计，包括文件存储方案、并发安全策略和数据迁移方案。

## 1. 文件存储方案

### 1.1 数据文件结构

```
data/
├── queue.json          # 待执行任务队列
├── scheduled.json      # 定时任务配置
├── running.json        # 当前运行任务
├── completed.json      # 已完成任务历史
└── failed.json         # 失败任务记录
```

### 1.2 目录初始化

```python
from pathlib import Path

DATA_DIR = Path("data")

def init_data_dir() -> None:
    """初始化数据目录"""
    DATA_DIR.mkdir(exist_ok=True)

    # 初始化空的 JSON 文件
    for filename in ["queue.json", "scheduled.json", "running.json", "completed.json", "failed.json"]:
        filepath = DATA_DIR / filename
        if not filepath.exists():
            filepath.write_text(json.dumps({"tasks": []}, ensure_ascii=False))
```

### 1.3 JSON 文件读写

```python
import json
from pathlib import Path
from typing import TypeVar, Generic

T = TypeVar("T")

class JSONStorage(Generic[T]):
    """JSON 文件存储基类"""

    def __init__(self, filepath: Path):
        self.filepath = filepath

    def _read(self) -> dict:
        """读取 JSON 文件"""
        if not self.filepath.exists():
            return {"tasks": []}
        content = self.filepath.read_text(encoding="utf-8")
        return json.loads(content)

    def _write(self, data: dict) -> None:
        """写入 JSON 文件"""
        self.filepath.parent.mkdir(parents=True, exist_ok=True)
        self.filepath.write_text(
            json.dumps(data, ensure_ascii=False, indent=2),
            encoding="utf-8"
        )
```

### 1.4 队列存储实现

```python
from dataclasses import dataclass
from typing import Optional
from datetime import datetime

@dataclass
class QueueStorage:
    """任务队列存储"""
    filepath: Path = DATA_DIR / "queue.json"

    def add(self, task: "Task") -> None:
        """添加任务到队列"""
        data = self._read()
        data["tasks"].append(asdict(task))
        self._write(data)

    def get_all(self) -> list["Task"]:
        """获取所有队列任务"""
        data = self._read()
        return [Task(**t) for t in data.get("tasks", [])]

    def get(self, task_id: str) -> Optional["Task"]:
        """获取指定任务"""
        tasks = self.get_all()
        for task in tasks:
            if task.id == task_id:
                return task
        return None

    def remove(self, task_id: str) -> bool:
        """从队列中移除任务"""
        data = self._read()
        original_count = len(data["tasks"])
        data["tasks"] = [t for t in data["tasks"] if t["id"] != task_id]
        self._write(data)
        return len(data["tasks"]) < original_count

    def clear(self) -> None:
        """清空队列"""
        self._write({"tasks": []})
```

### 1.5 定时任务存储实现

```python
@dataclass
class ScheduledStorage:
    """定时任务存储"""
    filepath: Path = DATA_DIR / "scheduled.json"

    def save(self, task: "ScheduledTask") -> None:
        """保存或更新定时任务"""
        data = self._read()
        tasks = data.get("tasks", [])

        # 查找并更新或添加
        found = False
        for i, t in enumerate(tasks):
            if t["id"] == task.id:
                tasks[i] = asdict(task)
                found = True
                break

        if not found:
            tasks.append(asdict(task))

        self._write({"tasks": tasks})

    def get_all(self) -> list["ScheduledTask"]:
        """获取所有定时任务"""
        data = self._read()
        return [ScheduledTask(**t) for t in data.get("tasks", [])]

    def get(self, task_id: str) -> Optional["ScheduledTask"]:
        """获取指定定时任务"""
        tasks = self.get_all()
        for task in tasks:
            if task.id == task_id:
                return task
        return None

    def delete(self, task_id: str) -> bool:
        """删除定时任务"""
        data = self._read()
        original_count = len(data.get("tasks", []))
        data["tasks"] = [t for t in data["tasks"] if t["id"] != task_id]
        self._write(data)
        return len(data["tasks"]) < original_count

    def get_enabled(self) -> list["ScheduledTask"]:
        """获取所有已启用的定时任务"""
        return [t for t in self.get_all() if t.enabled]
```

### 1.6 运行中任务存储

```python
@dataclass
class RunningStorage:
    """运行中任务存储"""
    filepath: Path = DATA_DIR / "running.json"

    def add(self, task: "Task") -> None:
        """添加运行中的任务"""
        data = self._read()
        data["tasks"].append(asdict(task))
        self._write(data)

    def get_all(self) -> list["Task"]:
        """获取所有运行中任务"""
        data = self._read()
        return [Task(**t) for t in data.get("tasks", [])]

    def remove(self, task_id: str) -> Optional["Task"]:
        """移除运行中的任务"""
        data = self._read()
        removed_task = None
        for i, t in enumerate(data["tasks"]):
            if t["id"] == task_id:
                removed_task = Task(**t)
                data["tasks"].pop(i)
                break
        self._write(data)
        return removed_task

    def clear(self) -> None:
        """清空运行中任务"""
        self._write({"tasks": []})
```

### 1.7 历史任务存储

```python
from typing import Optional

@dataclass
class HistoryStorage:
    """历史任务存储（已完成/失败）"""
    MAX_HISTORY = 1000  # 最大历史记录数

    completed_filepath: Path = DATA_DIR / "completed.json"
    failed_filepath: Path = DATA_DIR / "failed.json"

    def add_completed(self, task: "Task") -> None:
        """添加已完成任务"""
        self._add(self.completed_filepath, task)

    def add_failed(self, task: "Task") -> None:
        """添加失败任务"""
        self._add(self.failed_filepath, task)

    def _add(self, filepath: Path, task: "Task") -> None:
        """添加任务到历史"""
        data = self._read(filepath)
        tasks = data.get("tasks", [])

        # 添加到列表开头（最新在前）
        tasks.insert(0, asdict(task))

        # 限制历史记录数量
        if len(tasks) > self.MAX_HISTORY:
            tasks = tasks[:self.MAX_HISTORY]

        self._write(filepath, {"tasks": tasks})

    def get_completed(
        self,
        page: int = 1,
        limit: int = 20
    ) -> tuple[list["Task"], int]:
        """获取已完成任务（分页）"""
        return self._get_paginated(self.completed_filepath, page, limit)

    def get_failed(
        self,
        page: int = 1,
        limit: int = 20
    ) -> tuple[list["Task"], int]:
        """获取失败任务（分页）"""
        return self._get_paginated(self.failed_filepath, page, limit)

    def _get_paginated(
        self,
        filepath: Path,
        page: int,
        limit: int
    ) -> tuple[list["Task"], int]:
        """分页获取历史任务"""
        data = self._read(filepath)
        tasks = [Task(**t) for t in data.get("tasks", [])]
        total = len(tasks)

        offset = (page - 1) * limit
        items = tasks[offset:offset + limit]

        return items, total

    def _read(self, filepath: Path) -> dict:
        """读取历史文件"""
        if not filepath.exists():
            return {"tasks": []}
        return json.loads(filepath.read_text(encoding="utf-8"))

    def _write(self, filepath: Path, data: dict) -> None:
        """写入历史文件"""
        filepath.parent.mkdir(parents=True, exist_ok=True)
        filepath.write_text(
            json.dumps(data, ensure_ascii=False, indent=2),
            encoding="utf-8"
        )
```

---

## 2. 并发安全策略

### 2.1 文件锁机制

使用 `fcntl`（Unix）或 `msvcrt`（Windows）实现文件锁：

```python
import fcntl
import msvcrt
import os
from contextlib import contextmanager
from pathlib import Path
from typing import Optional

class FileLock:
    """文件锁实现"""

    def __init__(self, filepath: Path):
        self.filepath = filepath
        self.lock_path = filepath.with_suffix(filepath.suffix + ".lock")
        self._lock_file: Optional[int] = None

    def acquire(self, blocking: bool = True) -> bool:
        """获取文件锁"""
        # 创建锁文件
        self._lock_file = os.open(
            self.lock_path,
            os.O_CREAT | os.O_RDWR
        )

        try:
            if os.name == "nt":
                # Windows: 使用 msvcrt
                flags = 0 if blocking else msvcrt.LK_NBLCK
                msvcrt.locking(self._lock_file, flags, 1)
                return True
            else:
                # Unix: 使用 fcntl
                lock_type = fcntl.LOCK_EX if blocking else fcntl.LOCK_EX | fcntl.LOCK_NB
                fcntl.flock(self._lock_file, lock_type)
                return True
        except (IOError, OSError):
            self.release()
            return False

    def release(self) -> None:
        """释放文件锁"""
        if self._lock_file is not None:
            try:
                if os.name == "nt":
                    msvcrt.locking(self._lock_file, msvcrt.LK_UNLCK, 1)
                os.close(self._lock_file)
            except (IOError, OSError):
                pass
            finally:
                self._lock_file = None
                # 删除锁文件
                if self.lock_path.exists():
                    self.lock_path.unlink()

    def __enter__(self) -> "FileLock":
        self.acquire()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb) -> None:
        self.release()
```

### 2.2 原子写入

使用临时文件 + 重命名实现原子写入：

```python
import json
import tempfile
from pathlib import Path

def atomic_write(filepath: Path, data: dict) -> None:
    """原子写入 JSON 文件"""
    # 创建临时文件
    fd, temp_path = tempfile.mkstemp(
        dir=filepath.parent,
        suffix=".tmp"
    )

    try:
        # 写入临时文件
        with os.fdopen(fd, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        # 原子重命名
        os.replace(temp_path, filepath)
    except Exception:
        # 失败时删除临时文件
        if Path(temp_path).exists():
            Path(temp_path).unlink()
        raise
```

### 2.3 带锁的存储操作

```python
from typing import TypeVar, Generic
from dataclasses import dataclass

T = TypeVar("T")

class LockedStorage(Generic[T]):
    """带文件锁的存储基类"""

    def __init__(self, filepath: Path):
        self.filepath = filepath
        self.lock = FileLock(filepath)

    def _read(self) -> dict:
        """读取数据"""
        with self.lock:
            if not self.filepath.exists():
                return {"tasks": []}
            return json.loads(self.filepath.read_text(encoding="utf-8"))

    def _write(self, data: dict) -> None:
        """写入数据（带锁和原子操作）"""
        with self.lock:
            atomic_write(self.filepath, data)

    @contextmanager
    def transaction(self):
        """事务上下文管理器"""
        with self.lock:
            # 读取当前数据
            data = self._read()
            original = json.loads(json.dumps(data))  # 深拷贝

            try:
                yield data
                # 写入更新后的数据
                self._write(data)
            except Exception:
                # 失败时回滚
                self._write(original)
                raise
```

### 2.4 并发场景处理

| 场景 | 处理策略 |
|------|----------|
| 多个调度器实例 | 使用文件锁确保同一时间只有一个实例能写入 |
| 读写冲突 | 写操作使用独占锁，读操作可并发 |
| 写入失败 | 使用原子写入，失败时不影响原文件 |
| 锁超时 | 设置锁超时机制，避免死锁 |

### 2.5 锁超时配置

```python
# 配置常量
LOCK_TIMEOUT = 5  # 锁获取超时时间（秒）
LOCK_RETRY_INTERVAL = 0.1  # 重试间隔（秒）
MAX_LOCK_RETRIES = 50  # 最大重试次数

def acquire_lock_with_timeout(lock: FileLock) -> bool:
    """带超时的锁获取"""
    retries = 0
    while retries < MAX_LOCK_RETRIES:
        if lock.acquire(blocking=False):
            return True
        time.sleep(LOCK_RETRY_INTERVAL)
        retries += 1

    # 超时，尝试阻塞获取
    return lock.acquire(blocking=True)
```

---

## 3. 数据迁移方案

### 3.1 数据版本管理

```python
from enum import IntEnum

class DataVersion(IntEnum):
    """数据版本号"""
    V1 = 1  # 初始版本
    CURRENT = V1

# 数据文件头信息
DATA_HEADER = {
    "version": DataVersion.CURRENT,
    "created_at": "2024-01-01T00:00:00Z",
    "last_migrated_at": None
}
```

### 3.2 数据文件结构

```json
{
  "version": 1,
  "migrated_at": "2024-01-15T10:00:00Z",
  "tasks": [...]
}
```

### 3.3 迁移管理器

```python
from typing import Callable
from datetime import datetime

MigrationFn = Callable[[dict], dict]

class MigrationManager:
    """数据迁移管理器"""

    def __init__(self, data_dir: Path):
        self.data_dir = data_dir
        self.migrations: dict[int, MigrationFn] = {}

    def register(self, from_version: int, migration_fn: MigrationFn) -> None:
        """注册迁移函数"""
        self.migrations[from_version] = migration_fn

    def migrate_file(self, filepath: Path) -> dict:
        """迁移单个数据文件"""
        if not filepath.exists():
            return {"version": DataVersion.CURRENT, "tasks": []}

        data = json.loads(filepath.read_text(encoding="utf-8"))

        # 获取当前版本
        current_version = data.get("version", 1)

        # 执行迁移
        while current_version < DataVersion.CURRENT:
            migration_fn = self.migrations.get(current_version)
            if migration_fn:
                data = migration_fn(data)
                current_version += 1

            # 更新版本信息
            data["version"] = DataVersion.CURRENT
            data["migrated_at"] = datetime.now().isoformat() + "Z"

        return data
```

### 3.4 迁移示例

```python
def migration_v1_to_v2(data: dict) -> dict:
    """V1 到 V2 的迁移示例"""

    # 示例：添加新字段
    for task in data.get("tasks", []):
        if "new_field" not in task:
            task["new_field"] = "default_value"

    return data

# 注册迁移
manager = MigrationManager(DATA_DIR)
manager.register(1, migration_v1_to_v2)
```

### 3.5 迁移策略

| 场景 | 策略 |
|------|------|
| 新增字段 | 使用默认值填充 |
| 删除字段 | 保留数据，仅不使用 |
| 字段重命名 | 创建新字段，复制数据 |
| 数据格式变更 | 转换函数处理 |

### 3.6 迁移检查点

```python
def verify_migration(filepath: Path) -> bool:
    """验证迁移结果"""
    try:
        data = json.loads(filepath.read_text(encoding="utf-8"))

        # 检查必要字段
        assert "version" in data
        assert data["version"] == DataVersion.CURRENT
        assert "tasks" in data

        # 检查 JSON 格式有效
        json.dumps(data)
        return True
    except Exception:
        return False
```

### 3.7 启动时自动迁移

```python
def ensure_data_migrated() -> None:
    """确保数据已迁移到最新版本"""
    manager = MigrationManager(DATA_DIR)

    for filename in ["queue.json", "scheduled.json", "running.json",
                     "completed.json", "failed.json"]:
        filepath = DATA_DIR / filename

        # 迁移数据
        migrated_data = manager.migrate_file(filepath)

        # 验证迁移结果
        if verify_migration(filepath):
            # 写入迁移后的数据
            atomic_write(filepath, migrated_data)
            print(f"Migrated {filename} to version {DataVersion.CURRENT}")
```

---

## 4. 存储层 API

### 4.1 统一存储接口

```python
from abc import ABC, abstractmethod

class TaskStorage(ABC):
    """任务存储接口"""

    @abstractmethod
    def add_to_queue(self, task: Task) -> None:
        pass

    @abstractmethod
    def get_queue(self) -> list[Task]:
        pass

    @abstractmethod
    def remove_from_queue(self, task_id: str) -> bool:
        pass

    @abstractmethod
    def clear_queue(self) -> None:
        pass


class ScheduledTaskStorage(ABC):
    """定时任务存储接口"""

    @abstractmethod
    def create(self, task: ScheduledTask) -> None:
        pass

    @abstractmethod
    def get_all(self) -> list[ScheduledTask]:
        pass

    @abstractmethod
    def get(self, task_id: str) -> Optional[ScheduledTask]:
        pass

    @abstractmethod
    def update(self, task: ScheduledTask) -> None:
        pass

    @abstractmethod
    def delete(self, task_id: str) -> bool:
        pass


class TaskHistoryStorage(ABC):
    """任务历史存储接口"""

    @abstractmethod
    def add_completed(self, task: Task) -> None:
        pass

    @abstractmethod
    def add_failed(self, task: Task) -> None:
        pass

    @abstractmethod
    def get_completed(self, page: int, limit: int) -> tuple[list[Task], int]:
        pass

    @abstractmethod
    def get_failed(self, page: int, limit: int) -> tuple[list[Task], int]:
        pass
```

### 4.2 存储工厂

```python
class StorageFactory:
    """存储工厂"""

    @staticmethod
    def create_queue_storage() -> TaskStorage:
        return LockedStorage[Task](DATA_DIR / "queue.json")

    @staticmethod
    def create_scheduled_storage() -> ScheduledTaskStorage:
        return LockedStorage[ScheduledTask](DATA_DIR / "scheduled.json")

    @staticmethod
    def create_running_storage() -> "RunningStorage":
        return RunningStorage(DATA_DIR / "running.json")

    @staticmethod
    def create_history_storage() -> TaskHistoryStorage:
        return HistoryStorage()
```

---

## 5. 错误处理

### 5.1 存储异常

```python
class StorageError(Exception):
    """存储层异常基类"""
    pass

class FileNotFoundError(StorageError):
    """文件不存在"""
    pass

class LockTimeoutError(StorageError):
    """获取文件锁超时"""
    pass

class MigrationError(StorageError):
    """数据迁移失败"""
    pass
```

### 5.2 异常处理策略

| 异常类型 | 处理方式 |
|----------|----------|
| FileNotFoundError | 初始化数据目录和文件 |
| LockTimeoutError | 重试或返回错误 |
| JSONDecodeError | 记录错误，返回空数据 |
| MigrationError | 回滚更改，报告错误 |

---

## 6. 配置项

| 配置项 | 默认值 | 说明 |
|--------|--------|------|
| DATA_DIR | data/ | 数据文件目录 |
| MAX_HISTORY | 1000 | 历史记录最大数量 |
| LOCK_TIMEOUT | 5 | 文件锁超时（秒） |
| LOCK_RETRY_INTERVAL | 0.1 | 锁重试间隔（秒） |
| MAX_LOCK_RETRIES | 50 | 最大重试次数 |
